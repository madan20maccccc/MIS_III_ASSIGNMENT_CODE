# ğŸ§® MIS III Assignment â€“ Diabetes Classification Using SVM & SVD  
### *Mathematics for Intelligent Systems â€“ Model Building & Optimization*

This repository contains the Google Colab notebook **MIS_assignment.ipynb**, implementing multiple machine-learning modelsâ€”including SVM, SVD+SVM, Decision Tree, and Random Forestâ€”for diabetes prediction using the Pima Indians Diabetes Dataset.

---

## ğŸ“Œ Objectives
1. Load and understand the dataset.
2. Identify and replace medically impossible zero values using median imputation.
3. Split data into training, validation, and test sets (60â€“20â€“20).
4. Train a **Baseline SVM** model.
5. Build a **Truncated SVD + SVM** dimensionality-reduction pipeline.
6. Optimize the SVD+SVM pipeline using **RandomizedSearchCV**.
7. Train **Decision Tree** and **Random Forest** models.
8. Compare all models using evaluation metrics and visualizations.

---

## ğŸ—‚ï¸ Notebook Workflow

### ğŸ”¹ Step 1 â€” Load the Dataset
- Read CSV file  
- Display head(), describe(), and column names  
- Verify data structure and ranges  

### ğŸ”¹ Step 2 â€” Data Cleaning
Medical features containing invalid zero values:
- Glucose  
- Blood Pressure  
- Skin Thickness  
- Insulin  
- BMI  

Cleaning steps:
- Replace zeros â†’ NaN  
- Fill NaN with **median** of respective column  

### ğŸ”¹ Step 3 â€” Dataset Splitting
- 60% â†’ Training  
- 20% â†’ Validation  
- 20% â†’ Testing  
- Stratified splitting to maintain class balance  

---

## ğŸ’» Models Implemented

### 1ï¸âƒ£ Baseline SVM (No SVD)
- StandardScaler â†’ SVM (RBF kernel)  
- Evaluated using accuracy, F1, precision, recall  


### 2ï¸âƒ£ SVD + SVM Pipeline
Pipeline:
- Dimensionality reduction  
- Improved recall and F1 over baseline  

### 3ï¸âƒ£ Optimized SVD + SVM
Optimized parameters via RandomizedSearchCV:
- SVD components  
- Kernel  
- C  
- Gamma  

### 4ï¸âƒ£ Decision Tree Classifier
- Simple and interpretable baseline model  

### 5ï¸âƒ£ Random Forest Classifier
- Ensemble-based improvement over Decision Tree  

---

## ğŸ“Š Evaluation Metrics
Each model is evaluated using:
- Accuracy  
- F1-score  
- Precision  
- Recall  
- Confusion Matrix  
- ROC-AUC  

---

## ğŸ“ˆ Model Comparison Summary

| Model | Accuracy | F1-Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| Baseline SVM | 0.7468 | 0.5806 | 0.6750 | 0.5094 |
| SVD + SVM (3 Components) | 0.7403 | **0.6154** | 0.6275 | **0.6038** |
| Optimized SVD + SVM | 0.7338 | 0.5591 | **0.6500** | 0.4906 |
| Random Forest | 0.7078 | 0.5714 | 0.5769 | 0.5660 |
| Decision Tree | 0.6883 | 0.5472 | 0.5472 | 0.5472 |

### ğŸ” Key Insights
- **Best Recall:** SVD + SVM (3 components)  
- **Best Precision & AUC:** Optimized SVD + SVM  
- **Best overall balance:** SVD + SVM (3 components)  
- **Most stable tree model:** Random Forest  

---

## ğŸš€ Technologies Used
- Python 3  
- Pandas  
- NumPy  
- scikit-learn  
- Matplotlib  
- Seaborn  
- Google Colab  

---

## â–¶ï¸ How to Run
1. Open the `.ipynb` notebook in **Google Colab** or Jupyter Notebook.  
2. Upload the dataset or set correct dataset path.  
3. Run all cells sequentially.  
4. View outputs, evaluations, and visualizations.  

---

## ğŸ‘¤ Authors
**Madan M** (DL.AI.U4AID24021)  
**Anna Clara Mathew** (DL.AI.U4AID24005)  
**Lakxmi Chinmaya Aditya Katharu** (DL.AI.U4AID24018)  

B.Tech AI & DS (Medical Engineering)  
Amrita Vishwa Vidyapeetham â€“ Faridabad Campus  

---

## ğŸ“„ License
This project is for academic and research purposes only.
